{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-949e2bc81f7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dateutil import parser\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from lightgbm import LGBMClassifier\n",
    "print('Library Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = './diabetes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correlation matrix\n",
    "corrmat = df.corr()\n",
    "fig = plt.figure(figsize = (12, 12))\n",
    "\n",
    "sns.heatmap(corrmat, vmax = 1, square = True,annot=True,vmin=-1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(12,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue='Outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for unbalance \n",
    "df.Outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "# rows in dataframe 768\n-------------------------------------------\n# rows missing Glucose: 5\n# rows missing BloodPressure: 35\n# rows missing SkinThickness: 227\n# rows missing insulin: 374\n# rows missing bmi: 11\n# rows missing Age: 0\n# rows missing Pregnancies: 111\n# rows missing DiabetesPedigreeFunction: 0\n"
    }
   ],
   "source": [
    "print(\"# rows in dataframe {0}\".format(len(df)))\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"# rows missing Glucose: {0}\".format(len(df.loc[df.Glucose == 0 ])))\n",
    "print(\"# rows missing BloodPressure: {0}\".format(len(df.loc[df.BloodPressure == 0 ])))\n",
    "print(\"# rows missing SkinThickness: {0}\".format(len(df.loc[df.SkinThickness == 0 ])))\n",
    "print(\"# rows missing insulin: {0}\".format(len(df.loc[df.Insulin == 0 ])))\n",
    "print(\"# rows missing bmi: {0}\".format(len(df.loc[df.BMI == 0 ])))\n",
    "print(\"# rows missing Age: {0}\".format(len(df.loc[df.Age == 0 ])))\n",
    "print(\"# rows missing Pregnancies: {0}\".format(len(df.loc[df.Pregnancies == 0 ])))\n",
    "print(\"# rows missing DiabetesPedigreeFunction: {0}\".format(len(df.loc[df.DiabetesPedigreeFunction == 0 ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training Set : 614\nTest Set : 154\nTraining labels : 614\nTest Labels : 154\n"
    }
   ],
   "source": [
    "X = df.drop('Outcome',axis=1) # predictor feature coloumns\n",
    "y = df.Outcome\n",
    "\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y, test_size = 0.20, random_state = 10)\n",
    "\n",
    "print('Training Set :',len(X_train))\n",
    "print('Test Set :',len(X_test))\n",
    "print('Training labels :',len(y_train))\n",
    "print('Test Labels :',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'Imputer' from 'sklearn.preprocessing' (C:\\Users\\mrina\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\preprocessing\\__init__.py)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0a5e3a7bcaaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#impute with mean all 0 readings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfill\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Imputer' from 'sklearn.preprocessing' (C:\\Users\\mrina\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\preprocessing\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "#impute with mean all 0 readings\n",
    "\n",
    "fill = Imputer(missing_values = 0 , strategy =\"mean\", axis=0)\n",
    "\n",
    "X_train = fill.fit_transform(X_train)\n",
    "X_test = fill.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set : 614\n",
      "Test Set : 154\n",
      "Training labels : 614\n",
      "Test Labels : 154\n"
     ]
    }
   ],
   "source": [
    "print('Training Set :',len(X_train))\n",
    "print('Test Set :',len(X_test))\n",
    "print('Training labels :',len(y_train))\n",
    "print('Test Labels :',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FitModel(X_train,y_train,X_test,y_test,algo_name,algorithm,gridSearchParams,cv):\n",
    "    np.random.seed(10)\n",
    "   \n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=algorithm,\n",
    "        param_grid=gridSearchParams,\n",
    "        cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    \n",
    "    \n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    best_params = grid_result.best_params_\n",
    "    pred = grid_result.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "   # metrics =grid_result.gr\n",
    "    print(pred)\n",
    "    #pickle.dump(grid_result,open(algo_name,'wb'))\n",
    "   \n",
    "    print('Best Params :',best_params)\n",
    "    print('Classification Report :',classification_report(y_test,pred))\n",
    "    print('Accuracy Score : ' + str(accuracy_score(y_test,pred)))\n",
    "    print('Confusion Matrix : \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1\n",
      " 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 0\n",
      " 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1\n",
      " 1 0 0 0 1 0]\n",
      "Best Params : {'C': 1.0, 'penalty': 'l1'}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82        95\n",
      "           1       0.78      0.53      0.63        59\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.76      0.72      0.72       154\n",
      "weighted avg       0.76      0.76      0.75       154\n",
      "\n",
      "Accuracy Score : 0.7597402597402597\n",
      "Confusion Matrix : \n",
      " [[86  9]\n",
      " [28 31]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.2s finished\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "FitModel(X_train,y_train,X_test,y_test,'LogisticRegression',LogisticRegression(),hyperparameters,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1350 out of 1350 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0\n",
      " 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 1 0 1 0 1 1\n",
      " 1 1 0 0 1 0]\n",
      "Best Params : {'learning_rate': 0.04, 'max_depth': 7, 'n_estimators': 100}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81        95\n",
      "           1       0.71      0.66      0.68        59\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.75      0.75       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "Accuracy Score : 0.7662337662337663\n",
      "Confusion Matrix : \n",
      " [[79 16]\n",
      " [20 39]]\n"
     ]
    }
   ],
   "source": [
    "param ={\n",
    "            'n_estimators': [100, 500, 1000,1500, 2000],\n",
    "            'max_depth' :[2,3,4,5,6,7],\n",
    "    'learning_rate':np.arange(0.01,0.1,0.01).tolist()\n",
    "           \n",
    "        }\n",
    "\n",
    "FitModel(X_train,y_train,X_test,y_test,'XGBoost',XGBClassifier(),param,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1\n",
      " 1 0 0 0 1 0]\n",
      "Best Params : {'n_estimators': 1500}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80        95\n",
      "           1       0.70      0.53      0.60        59\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.73      0.69      0.70       154\n",
      "weighted avg       0.73      0.73      0.72       154\n",
      "\n",
      "Accuracy Score : 0.7337662337662337\n",
      "Confusion Matrix : \n",
      " [[82 13]\n",
      " [28 31]]\n"
     ]
    }
   ],
   "source": [
    "param ={\n",
    "            'n_estimators': [100, 500, 1000,1500, 2000],\n",
    "           \n",
    "        }\n",
    "FitModel(X_train,y_train,X_test,y_test,'Random Forest',RandomForestClassifier(),param,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1\n",
      " 1 0 0 0 0 0]\n",
      "Best Params : {'C': 1, 'gamma': 0.0001}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.80        95\n",
      "           1       0.73      0.41      0.52        59\n",
      "\n",
      "    accuracy                           0.71       154\n",
      "   macro avg       0.72      0.66      0.66       154\n",
      "weighted avg       0.72      0.71      0.69       154\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n",
      "Confusion Matrix : \n",
      " [[86  9]\n",
      " [35 24]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "param ={\n",
    "            'C': [0.1, 1, 100, 1000],\n",
    "            'gamma': [0.0001, 0.001, 0.005, 0.1, 1, 3, 5]\n",
    "        }\n",
    "FitModel(X_train,y_train,X_test,y_test,'SVC',SVC(),param,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the Dataset - Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm =SMOTE(random_state=42)\n",
    "X_res_OS , Y_res_OS = sm.fit_resample(X,y)\n",
    "pd.Series(Y_res_OS).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set : 800\n",
      "Test Set : 200\n",
      "Training labels : 800\n",
      "Test Labels : 200\n"
     ]
    }
   ],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X_res_OS, Y_res_OS, test_size = 0.20, random_state = 10)\n",
    "\n",
    "print('Training Set :',len(X_train))\n",
    "print('Test Set :',len(X_test))\n",
    "print('Training labels :',len(y_train))\n",
    "print('Test Labels :',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fill = Imputer(missing_values = 0 , strategy =\"mean\", axis=0)\n",
    "\n",
    "X_train = fill.fit_transform(X_train)\n",
    "X_test = fill.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set : 800\n",
      "Test Set : 200\n",
      "Training labels : 800\n",
      "Test Labels : 200\n"
     ]
    }
   ],
   "source": [
    "print('Training Set :',len(X_train))\n",
    "print('Test Set :',len(X_test))\n",
    "print('Training labels :',len(y_train))\n",
    "print('Test Labels :',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - After Over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1\n",
      " 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0\n",
      " 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0\n",
      " 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0]\n",
      "Best Params : {'C': 1.0, 'penalty': 'l2'}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70        93\n",
      "           1       0.74      0.70      0.72       107\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.71      0.71      0.71       200\n",
      "weighted avg       0.71      0.71      0.71       200\n",
      "\n",
      "Accuracy Score : 0.71\n",
      "Confusion Matrix : \n",
      " [[67 26]\n",
      " [32 75]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "FitModel(X_train,y_train,X_test,y_test,'LogisticRegression',LogisticRegression(),hyperparameters,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost  - After Over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1350 out of 1350 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0\n",
      " 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1\n",
      " 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 0 1 1 1 1 0 0\n",
      " 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0]\n",
      "Best Params : {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79        93\n",
      "           1       0.82      0.83      0.82       107\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.81      0.81      0.81       200\n",
      "weighted avg       0.81      0.81      0.81       200\n",
      "\n",
      "Accuracy Score : 0.81\n",
      "Confusion Matrix : \n",
      " [[73 20]\n",
      " [18 89]]\n"
     ]
    }
   ],
   "source": [
    "param ={\n",
    "            'n_estimators': [100, 500, 1000,1500, 2000],\n",
    "            'max_depth' :[2,3,4,5,6,7],\n",
    "    'learning_rate':np.arange(0.01,0.1,0.01).tolist()\n",
    "           \n",
    "        }\n",
    "\n",
    "FitModel(X_train,y_train,X_test,y_test,'XGBoost',XGBClassifier(),param,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest  - After Over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1\n",
      " 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0\n",
      " 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0]\n",
      "Best Params : {'n_estimators': 100}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82        93\n",
      "           1       0.83      0.88      0.85       107\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.84      0.84      0.84       200\n",
      "weighted avg       0.84      0.84      0.84       200\n",
      "\n",
      "Accuracy Score : 0.84\n",
      "Confusion Matrix : \n",
      " [[74 19]\n",
      " [13 94]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    3.8s finished\n"
     ]
    }
   ],
   "source": [
    "param ={\n",
    "            'n_estimators': [100, 500, 1000,1500, 2000],\n",
    "           \n",
    "        }\n",
    "FitModel(X_train,y_train,X_test,y_test,'Random Forest',RandomForestClassifier(),param,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC  - After Over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1\n",
      " 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0\n",
      " 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0]\n",
      "Best Params : {'C': 1, 'gamma': 0.005}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        93\n",
      "           1       0.79      0.77      0.78       107\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.76      0.76      0.76       200\n",
      "weighted avg       0.77      0.77      0.77       200\n",
      "\n",
      "Accuracy Score : 0.765\n",
      "Confusion Matrix : \n",
      " [[71 22]\n",
      " [25 82]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "param ={\n",
    "            'C': [0.1, 1, 100, 1000],\n",
    "            'gamma': [0.0001, 0.001, 0.005, 0.1, 1, 3, 5]\n",
    "        }\n",
    "FitModel(X_train,y_train,X_test,y_test,'SVC',SVC(),param,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}